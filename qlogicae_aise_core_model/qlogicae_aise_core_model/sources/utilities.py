import os
import csv
import json
import torch
import shutil
import random
import argparse
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt


IS_VERBOSE_LOGGING_ENABLED = False
IS_PREPARING_DATASET_ENABLED = True
IS_TRAINING_MODEL_ENABLED = True
IS_TESTING_MODEL_ENABLED = True
IS_TESTING_MODEL_OUTPUT_VERBOSE_ENABLED = False


NUMBER_OF_SAMPLES = 10000
TRAINING_TESTING_RATIO = 0.7
TRAINING_POSITION_RATIO = 0.4
TESTING_POSITION_RATIO = 0.4

RELATIVE_QLOGICAE_DOT_QLOGICAE_AI_FOLDER_PATH = "qlogicae/.qlogicae/application"

RELATIVE_ROOT_DATASET_FOLDER_PATH = f"{RELATIVE_QLOGICAE_DOT_QLOGICAE_AI_FOLDER_PATH}/ai/datasets"
RELATIVE_TRAINING_FILE_PATH = "training.csv"
RELATIVE_TESTING_FILE_PATH = "testing.csv"

FULL_TRAINING_FILE_PATH = os.path.join(RELATIVE_ROOT_DATASET_FOLDER_PATH, RELATIVE_TRAINING_FILE_PATH)
FULL_TESTING_FILE_PATH = os.path.join(RELATIVE_ROOT_DATASET_FOLDER_PATH, RELATIVE_TESTING_FILE_PATH)


RELATIVE_ROOT_AI_PATH = f"{RELATIVE_QLOGICAE_DOT_QLOGICAE_AI_FOLDER_PATH}/templates/default/build/qlogicae/application/ai"
RELATIVE_ROOT_MODELS_PATH = f"{RELATIVE_ROOT_AI_PATH}/models"
RELATIVE_ROOT_ENCODINGS_PATH = f"{RELATIVE_ROOT_AI_PATH}/encodings"

RELATIVE_MODELS_PTH_PATH = "model.pth"
RELATIVE_MODELS_ONNX_PATH = "model.onnx"
RELATIVE_VOCABULARY_FILE_PATH = "vocabulary.json"

FULL_MODELS_PTH_PATH = os.path.join(RELATIVE_ROOT_MODELS_PATH, RELATIVE_MODELS_PTH_PATH)
FULL_MODELS_ONNX_PATH = os.path.join(RELATIVE_ROOT_MODELS_PATH, RELATIVE_MODELS_ONNX_PATH)
FULL_VOCABULARY_FILE_PATH = os.path.join(RELATIVE_ROOT_ENCODINGS_PATH, RELATIVE_VOCABULARY_FILE_PATH)

RELATIVE_ROOT_LOGS_PATH = f"{RELATIVE_QLOGICAE_DOT_QLOGICAE_AI_FOLDER_PATH}/ai/logs"
RELATIVE_ROOT_LOGS_TRAINING_PATH = "training"
RELATIVE_LOGS_TRAINING_LOG_CSV_FILE_PATH = "logs.csv"
RELATIVE_LOGS_TRAINING_LOG_JSON_FILE_PATH = "logs.json"
RELATIVE_LOGS_TRAINING_TRAINING_LOSS_PNG_FILE_PATH = "training_loss.png"
RELATIVE_LOGS_TRAINING_TRAINING_ACCURACY_PNG_FILE_PATH = "training_accuracy.png"
RELATIVE_LOGS_TRAINING_VALUE_LOSS_PNG_FILE_PATH = "value_loss.png"
RELATIVE_LOGS_TRAINING_VALUE_ACCURACY_PNG_FILE_PATH = "value_accuracy.png"
RELATIVE_LOGS_TRAINING_LEARNING_RATE_PNG_FILE_PATH = "learning_rate.png"
RELATIVE_LOGS_TRAINING_TRAINING_LOSS_AND_ACCURACY_PNG_FILE_PATH = "training_loss_and_accuracy.png"
RELATIVE_LOGS_TRAINING_VALUE_LOSS_AND_ACCURACY_PNG_FILE_PATH = "value_loss_and_accuracy.png"
RELATIVE_LOGS_TRAINING_TRAINING_AND_VALUE_LOSS_PNG_FILE_PATH = "training_and_value_loss.png"
RELATIVE_LOGS_TRAINING_TRAINING_AND_VALUE_ACCURACY_PNG_FILE_PATH = "training_and_value_accuracy.png"
RELATIVE_LOGS_TRAINING_TRAINING_AND_VALUE_PNG_FILE_PATH = "training_and_value.png"
RELATIVE_LOGS_TRAINING_LEARNING_DURATION_PNG_FILE_PATH = "learning_duration.png"

FULL_LOGS_TRAINING_LOG_FOLDER_PATH = os.path.join(RELATIVE_ROOT_LOGS_PATH, RELATIVE_ROOT_LOGS_TRAINING_PATH)
FULL_LOGS_TRAINING_LOG_CSV_FILE_PATH = os.path.join(FULL_LOGS_TRAINING_LOG_FOLDER_PATH, RELATIVE_LOGS_TRAINING_LOG_CSV_FILE_PATH)
FULL_LOGS_TRAINING_LOG_JSON_FILE_PATH = os.path.join(FULL_LOGS_TRAINING_LOG_FOLDER_PATH, RELATIVE_LOGS_TRAINING_LOG_JSON_FILE_PATH)
FULL_LOGS_TRAINING_TRAINING_LOSS_PNG_FILE_PATH = os.path.join(FULL_LOGS_TRAINING_LOG_FOLDER_PATH, RELATIVE_LOGS_TRAINING_TRAINING_LOSS_PNG_FILE_PATH)
FULL_LOGS_TRAINING_TRAINING_ACCURACY_PNG_FILE_PATH = os.path.join(FULL_LOGS_TRAINING_LOG_FOLDER_PATH, RELATIVE_LOGS_TRAINING_TRAINING_ACCURACY_PNG_FILE_PATH)
FULL_LOGS_TRAINING_VALUE_LOSS_PNG_FILE_PATH = os.path.join(FULL_LOGS_TRAINING_LOG_FOLDER_PATH, RELATIVE_LOGS_TRAINING_VALUE_LOSS_PNG_FILE_PATH)
FULL_LOGS_TRAINING_VALUE_ACCURACY_PNG_FILE_PATH = os.path.join(FULL_LOGS_TRAINING_LOG_FOLDER_PATH, RELATIVE_LOGS_TRAINING_VALUE_ACCURACY_PNG_FILE_PATH)
FULL_LOGS_TRAINING_LEARNING_RATE_PNG_FILE_PATH = os.path.join(FULL_LOGS_TRAINING_LOG_FOLDER_PATH, RELATIVE_LOGS_TRAINING_LEARNING_RATE_PNG_FILE_PATH)
FULL_LOGS_TRAINING_TRAINING_LOSS_AND_ACCURACY_PNG_FILE_PATH = os.path.join(FULL_LOGS_TRAINING_LOG_FOLDER_PATH, RELATIVE_LOGS_TRAINING_TRAINING_LOSS_AND_ACCURACY_PNG_FILE_PATH)
FULL_LOGS_TRAINING_VALUE_LOSS_AND_ACCURACY_PNG_FILE_PATH = os.path.join(FULL_LOGS_TRAINING_LOG_FOLDER_PATH, RELATIVE_LOGS_TRAINING_VALUE_LOSS_AND_ACCURACY_PNG_FILE_PATH)
FULL_LOGS_TRAINING_TRAINING_AND_VALUE_LOSS_PNG_FILE_PATH = os.path.join(FULL_LOGS_TRAINING_LOG_FOLDER_PATH, RELATIVE_LOGS_TRAINING_TRAINING_AND_VALUE_LOSS_PNG_FILE_PATH)
FULL_LOGS_TRAINING_TRAINING_AND_VALUE_ACCURACY_PNG_FILE_PATH = os.path.join(FULL_LOGS_TRAINING_LOG_FOLDER_PATH, RELATIVE_LOGS_TRAINING_TRAINING_AND_VALUE_ACCURACY_PNG_FILE_PATH)
FULL_LOGS_TRAINING_TRAINING_AND_VALUE_PNG_FILE_PATH = os.path.join(FULL_LOGS_TRAINING_LOG_FOLDER_PATH, RELATIVE_LOGS_TRAINING_TRAINING_AND_VALUE_PNG_FILE_PATH)
FULL_LOGS_TRAINING_LEARNING_DURATION_PNG_FILE_PATH = os.path.join(FULL_LOGS_TRAINING_LOG_FOLDER_PATH, RELATIVE_LOGS_TRAINING_LEARNING_DURATION_PNG_FILE_PATH)



MODEL_TRAINING_SEED = 42
random.seed(MODEL_TRAINING_SEED)
np.random.seed(MODEL_TRAINING_SEED)
torch.manual_seed(MODEL_TRAINING_SEED)

EXPECTED_VOCABULARY_SIZE = 97
MAXIMUM_TRAINING_EPOCH = 50
BATCH_SIZE = 128
VALUE_SPLIT = 0.2
DEVICE_TYPE = device = "cuda" if torch.cuda.is_available() else "cpu"
GRAD_CLIP_NORM = 1.0
EARLY_STOPPING_PATIENCE = 10
SCHEDULER_FACTOR = 0.5
SCHEDULER_PATIENCE = 3
MAXIMUM_LEARNING_RATE = 1e-3
MINIMUM_LEARNING_RATE = 1e-6


def save_plot_png(title, x_label, y_label, data, file_output):
    plt.figure()

    for label, series in data.items():
        plt.plot(range(1, len(series) + 1), series, label=label)

    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.title(title)
    plt.legend()
    plt.grid(True)
    plt.savefig(file_output)
    plt.close()


def parse_console_arguments():
    parser = argparse.ArgumentParser()

    arguments = parser.parse_args()

    return arguments


def log_to_console(text):
    if IS_VERBOSE_LOGGING_ENABLED:
        print(text)


def clear_all_console_outputs():
    os.system("cls" if os.name == "nt" else "clear")


def write_csv(rows, filename):
    with open(filename, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["file_content","label"])
        for c,l in rows:
            writer.writerow([c,l])


def prepare_folder_recursively(path):
    if os.path.exists(path):
        for filename in os.listdir(path):
            file_path = os.path.join(path, filename)
            try:
                if os.path.isfile(file_path) or os.path.islink(file_path):
                    os.unlink(file_path)  
                elif os.path.isdir(file_path):
                    shutil.rmtree(file_path)  
            except Exception as e:
                print(f"Failed to delete {file_path}. Reason: {e}")
    else:
        os.makedirs(path)  

